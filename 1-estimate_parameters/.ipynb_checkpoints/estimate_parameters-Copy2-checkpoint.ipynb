{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate signal parameters\n",
    "\n",
    "Notation:\n",
    "* Capital letters refer to Fourier components, e.g.: `h` = $h(t)$ and `H` = $\\tilde h(f)$.\n",
    "* $s(t) = h(t) + n(t)$, (strain = template + noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex matched filtering:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "    z(t_0) &= \\frac{4}{\\sigma} \\int_0^\\infty \\frac{\\tilde s(f) \\tilde h_0^*(f)}{\\mathcal N(f)} e^{i 2\\pi f t_0}df\\,\\,\n",
    "\\in \\mathbb C \\\\\n",
    "    \\sigma^2 &= 4 \\int_0^\\infty \\frac{|\\tilde h_0(f)|^2}{\\mathcal N(f)}df\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$${\\rm SNR} = \\max |z|$$. \n",
    "\n",
    "$$\n",
    "{\\rm SNR_{\\rm ideal}} = 2\\sqrt{\\int_0^\\infty \\frac{|\\tilde h (f)|^2}{\\mathcal N(f)} df}\n",
    "$$\n",
    "\n",
    "I normalized $z(t_0)$ so that $\\langle z(t_0)^2 \\rangle_{t_0} = 2$, or ${\\rm rms}(z) = \\sqrt 2$.\n",
    "\n",
    "${\\rm SNR}$ should coincide with ${\\rm SNR_{ideal}}$ if the template was exactly right (including $D_{eff}$, and all PN terms). \n",
    "\n",
    "$z$ and ${\\rm SNR}$ are insensitive to $D_{\\rm eff}$, ${\\rm SNR_{ideal}}$ is sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import sin, cos, sqrt, pi, exp, fft\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.interpolate import interp1d, UnivariateSpline, griddata\n",
    "from scipy.signal import tukey, resample\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import pprint\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "* template parameters\n",
    "* the templates' sampling frequency \n",
    "* event data, and compute PSD \n",
    "* parameter values reported by LIGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#event = 'GW150914'\n",
    "#event = 'GW151226'\n",
    "#event = 'LVT151012'\n",
    "#event = 'GW170104'\n",
    "event = 'GW170608'\n",
    "#event = 'GW170814'\n",
    "\n",
    "approximants = ['IMRPhenomD',\n",
    "                'SEOBNRv4_ROM'\n",
    "               ]\n",
    "detectors = ['H1', 'L1'] if event in ['GW150914', 'GW151226', 'LVT151012', 'GW170104', 'GW170608']\\\n",
    "       else ['H1', 'L1', 'V1'] # In the same order as the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'GW170608/parameters' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b28b6c0d0f24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/parameters'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\s+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfreqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}/freqs.dat'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapproximants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/javier/.anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/javier/.anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/javier/.anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/javier/.anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/javier/.anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'GW170608/parameters' does not exist"
     ]
    }
   ],
   "source": [
    "parameters = pd.read_csv('{}/parameters'.format(event), sep = '\\s+')\n",
    "\n",
    "freqs = np.loadtxt('{}/{}/freqs.dat'.format(event, approximants[0]), unpack = True)\n",
    "df = freqs[1] - freqs[0]\n",
    "fs = 2 * freqs[-1]\n",
    "dt = 1. / fs # [s]\n",
    "N = 2 * len(freqs) - 1\n",
    "T = N / fs # [s]\n",
    "times = np.linspace(-T, 0, num = N, endpoint = False) # [s]\n",
    "if (fs != 4096.):\n",
    "    print('The sampling frequency of the templates should be 4096 Hz')\n",
    "    quit()\n",
    "f_isco = 4397. / (parameters.at[0, 'm1'] + parameters.at[0, 'm2']) # 4397 = c^3 / (6^1.5 * pi * G * M_sun)\n",
    "\n",
    "S, PSD = {}, {}\n",
    "for i, det in enumerate(detectors):\n",
    "    s = np.loadtxt('{0}/{0}.dat'.format(event), usecols = i, skiprows = 1) # LIGO data\n",
    "    psd, psd_freqs = mlab.psd(s, Fs = 4096, NFFT = 4096)\n",
    "    PSD[det] = np.interp(freqs, psd_freqs, psd) # [1/Hz]\n",
    "    \n",
    "    # Crop T seconds of data near the event:\n",
    "    s = s[len(s)//2 - 3*N//4: len(s)//2 + N//4]\n",
    "    S[det] = fft.rfft(s * tukey(len(s), alpha = 1./8)) / fs # [1/Hz] \n",
    "\n",
    "ligo_parameters = pd.read_csv('{0}/{0}_LIGO_parameters'.format(event), sep = '\\s+', comment = '#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot detector and template ASD \n",
    "... for the first template, for each approximant: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_cols = len(approximants)\n",
    "n_rows = 3\n",
    "plt.figure(figsize = (5 * n_cols, 3.5 * n_rows))\n",
    "\n",
    "z = {} # I want to store z\n",
    "f_high = 1e3 # Just for the plot limits, not for computations\n",
    "for col, approximant in enumerate(approximants):\n",
    "    H = np.genfromtxt('{}/{}/0.dat'.format(event, approximant), dtype = complex)\n",
    "    f_min = freqs[next(i for i, x in enumerate(H) if x != 0)]\n",
    "    \n",
    "    # Complex matched filter:\n",
    "    Z, z[approximant], SNR, D_eff = {}, {}, {}, {} # Detector dependent quantities\n",
    "    for det in detectors:\n",
    "        Z[det] = 2 * (S[det] * H.conjugate() / PSD[det]) / sqrt((abs(H)**2 / PSD[det] * df).sum())\n",
    "        z[approximant][det] = fft.ifft(Z[det] * fs, N)\n",
    "        SNR[det] = max(abs(z[approximant][det]))\n",
    "        SNR_ideal_1Mpc = sqrt((4*abs(H)**2 / PSD[det] * df).sum()) # If the template was exactly right\n",
    "        D_eff[det] = SNR_ideal_1Mpc / SNR[det]\n",
    "    SNR['Total'] = sqrt(sum([SNR[det]**2 for det in detectors]))\n",
    "    \n",
    "    # ASD:\n",
    "    ax1 = plt.subplot(n_rows, n_cols, col + 1)\n",
    "    plt.title('{} template for {}'.format(approximant, event))\n",
    "    for det in detectors:\n",
    "        plt.loglog(freqs, sqrt(PSD[det]), label = det)\n",
    "    plt.gca().set_prop_cycle(None) # Reset color cycle\n",
    "    for det in detectors:\n",
    "        plt.plot(freqs, 2*abs(H)*sqrt(freqs) / D_eff[det])\n",
    "    plt.axvline(f_isco, ls = ':', c = 'grey', label = '$f_{ISCO}$')\n",
    "    plt.ylim(5e-24, 1e-21)\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.ylabel(r'ASD, $2\\sqrt{f}|\\tilde h(f)|$   [$1/\\sqrt{\\rm Hz}$]')\n",
    "    plt.legend()\n",
    "\n",
    "    # Contribution to the SNR:\n",
    "    plt.subplot(n_rows, n_cols, n_cols + col + 1, sharex = ax1)\n",
    "    for det in detectors:\n",
    "        plt.semilogx(freqs, freqs * abs(H)**2 / D_eff[det]**2 / PSD[det], label = det)\n",
    "    plt.axvline(f_isco, ls = ':', c = 'grey', label = '$f_{ISCO}$')\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.ylabel(r'$f|\\tilde h(f)|^2/\\mathcal{N}(f)$')\n",
    "    plt.legend()\n",
    "    plt.xlim(f_min, f_high)\n",
    "\n",
    "    # |z|:\n",
    "    plt.subplot(n_rows, n_cols, n_cols * 2 + col + 1)\n",
    "    for det in detectors:\n",
    "        plt.plot(times + T/2, abs(z[approximant][det]), label = det)\n",
    "        rms = sqrt((abs(z[approximant][det][N//8: 7*N//8])**2).mean())\n",
    "        plt.axhline(rms, ls = ':')\n",
    "    plt.xlabel('$t_0 - t_c$ [s]')\n",
    "    plt.ylabel('Complex matched filter $|z(t_0)|$')\n",
    "    plt.legend()\n",
    "    \n",
    "    print('Using {} approximant:'.format(approximant))\n",
    "    print('  SNR:')\n",
    "    for x in SNR:\n",
    "        print('\\t{0}:\\t{1:.2f}'.format(x, SNR[x]))\n",
    "    print('  D_eff:')\n",
    "    for det in detectors:\n",
    "        print('\\t{0}:\\t{1:.0f} Mpc'.format(det, D_eff[det]))\n",
    "    print()\n",
    "plt.tight_layout();\n",
    "plt.savefig('{}/figures/matched_filtering.pdf'.format(event), bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase variation\n",
    "... within the width of the peak in $\\mathcal{L}(t_0)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = len(approximants)\n",
    "n_rows = len(detectors)\n",
    "plt.figure(figsize = (5 * n_cols, 3.5 * n_rows))\n",
    "dt0 = {}\n",
    "print('t0 uncertainty (half width at half-maximum) [s]:')\n",
    "for col, approximant in enumerate(approximants):\n",
    "    print(approximant)\n",
    "    dt0[approximant] = {}\n",
    "    for row, det in enumerate(detectors):\n",
    "        L = exp(abs(z[approximant][det])**2/2)\n",
    "        L *= 2*pi / max(L)\n",
    "        spline = UnivariateSpline(times, L - max(L) / 2, s = 0)\n",
    "        roots = spline.roots()[0:2] # Find the width of the peak\n",
    "        r1, r2 = roots[0:2]\n",
    "        if len(roots) != 2:\n",
    "            print('WARNING: Could not found a single peak for {}, {}'.format(approximant, det))\n",
    "        dt0[approximant][det] = (r2 - r1)/2\n",
    "        print('\\t{0}: {1:.3g}'.format(det, (r2 - r1)/2))\n",
    "        \n",
    "        phases = [x if x >= 0 else x + 2*pi for x in np.angle(z[approximant][det])] # in (0, 2pi)\n",
    "        y1, y2 = np.interp([r1, r2], times, phases)\n",
    "        \n",
    "        plt.subplot(n_rows, n_cols, n_cols * (row) + col + 1)\n",
    "        plt.plot(times, L, label = '$\\mathcal{L}$')\n",
    "        plt.plot(times, phases, label = '$\\phi$') # Phase\n",
    "        [plt.axhline(y, ls = ':', c = 'grey') for y in [0, 2*pi]]\n",
    "        if y1 < y2:\n",
    "            plt.axhspan(y1, y2, alpha = .3, color = 'orange')\n",
    "        else:\n",
    "            plt.axhspan(y1, 2 * pi, alpha = .3, color = 'orange')\n",
    "            plt.axhspan(0, y2, alpha = .3, color = 'orange')\n",
    "        ax = plt.gca()\n",
    "        ax.set_yticks([0, 2 * pi])\n",
    "        ax.set_yticklabels([0, '$2\\pi$'])\n",
    "        plt.xlim(r1 - .01, r2 + .01)\n",
    "        ax.set_xticks(ax.get_xticks()[::2])\n",
    "        plt.xlabel('$t_0$ [s]')\n",
    "        plt.ylabel('$\\phi$')\n",
    "        plt.title('{}, {}'.format(approximant, det))\n",
    "        plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('{}/figures/phase.pdf'.format(event), bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the SNR \n",
    "... of the templates, for each approximant used, using both detectors. Also store the $t_0$ of maximum likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recompute_SNR = False # False: use the previous SNR if available.\n",
    "\n",
    "if not any('SNR' in col_name for col_name in parameters.columns):\n",
    "    recompute_SNR = True\n",
    "\n",
    "def compute_SNR(n, approximant):\n",
    "    H = np.genfromtxt('{}/{}/{}.dat'.format(event, approximant, n), dtype = complex)\n",
    "    SNR, t0 = {}, {}\n",
    "    for det in detectors:\n",
    "        Z = 2 * (S[det] * H.conjugate() / PSD[det]) / sqrt((abs(H)**2 / PSD[det] * df).sum())\n",
    "        z_ = fft.ifft(Z * fs, N) # The underscore is to prevent conflict with previous z\n",
    "        argmax = np.argmax(abs(z_))\n",
    "        SNR[det] = abs(z_[argmax])\n",
    "        t0[det] = times[argmax]\n",
    "    return {'SNR': sqrt(sum([SNR[det]**2 for det in detectors])), 't0': t0}\n",
    "\n",
    "if recompute_SNR:\n",
    "    p = Pool(cpu_count())\n",
    "    for approximant in approximants:\n",
    "        results = p.starmap(compute_SNR, [[n, approximant] for n in parameters.index]) # Parallelize over n\n",
    "        parameters['SNR_{}'.format(approximant)] = [x['SNR'] for x in results]\n",
    "        for det in detectors:\n",
    "            parameters['t0_{}_{}'.format(approximant, det)] = [x['t0'][det] for x in results]\n",
    "    parameters.to_csv('{}/parameters'.format(event), sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot\n",
    "Define auxiliary things for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_approx(a, b, eps = 1e-5): # For slicing things with numerical error\n",
    "    return abs(a - b) < eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1_dict = {'name': 'm1', 'label': r'$m_1$', 'unit': '[$M_\\odot$]'}\n",
    "m2_dict = {'name': 'm2', 'label': r'$m_2$', 'unit': '[$M_\\odot$]'}\n",
    "M_chirp_dict = {'name': 'M_chirp', 'label': r'$\\mathcal{M}$', 'unit': '[$M_\\odot$]'}\n",
    "q_dict = {'name': 'q', 'label': r'$q$', 'unit': ''}\n",
    "chi_eff_dict = {'name': 'chi_eff', 'label': r'$\\chi_{\\rm eff}$', 'unit': ''}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the other mass and spin parameters $\\mathcal{M}, q, \\chi$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters['M_chirp'] = (parameters['m1'] * parameters['m2'])**.6 / (parameters['m1'] + parameters['m2'])**.2\n",
    "parameters['q'] = parameters['m2'] / parameters['m1']\n",
    "parameters['chi_eff'] = (parameters['m1'] * parameters['s1z'] + parameters['m2']*parameters['s2z']) \\\n",
    "                        / (parameters['m1'] + parameters['m2'])\n",
    "parameters['eta'] = parameters['m1'] * parameters['m2'] / (parameters['m1'] + parameters['m2'])**2\n",
    "parameters['chi_hat'] = (parameters['chi_eff'] - 38*parameters['eta']*(parameters['s1z']+parameters['s2z'])/113)\\\n",
    "                        / (1 - 76 * parameters['eta'] / 113)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the likelihood, normalized to max = 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for approximant in approximants:\n",
    "    L = exp(parameters['SNR_{}'.format(approximant)]**2/2)\n",
    "    parameters['likelihood_{}'.format(approximant)] = L / L.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $t_0$\n",
    "... as a function of other parameters. \n",
    "\n",
    "The errorbars here are estimates: for the parameters they are the ones reported by LIGO, for $\\Delta t_0$ the half-width at half maximum obtained for the first template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directions to plot: vary the first at fixed second and third:\n",
    "directions = [[M_chirp_dict, chi_eff_dict, q_dict], # vary M_chirp at fixed chi_eff, q\n",
    "              [q_dict, chi_eff_dict, M_chirp_dict], # vary q at fixed chi_eff, M_chirp\n",
    "              [chi_eff_dict, q_dict, M_chirp_dict] # vary chi_eff at fixed q, M_chirp\n",
    "             ]\n",
    "n_cols = len(approximants)\n",
    "n_rows = len(directions)\n",
    "\n",
    "plt.figure(figsize = (5 * n_cols, 3.5 * n_rows))\n",
    "for col, approximant in enumerate(approximants):\n",
    "    # Find the parameters with maximum likelihood:\n",
    "    max_likelihood = parameters.loc[parameters['likelihood_{}'.format(approximant)].idxmax()]\n",
    "    \n",
    "    # Vary x at constant (y, z):\n",
    "    for row, [x, y, z] in enumerate(directions):\n",
    "        x_line = parameters[is_approx(parameters[y['name']], max_likelihood[y['name']]) & \n",
    "                            is_approx(parameters[z['name']], max_likelihood[z['name']])]\n",
    "        \n",
    "        plt.subplot(n_rows, n_cols, n_cols * row + col + 1)\n",
    "        \n",
    "        for det in detectors:\n",
    "            plt.plot(x_line[x['name']], [(t0 - max_likelihood['t0_{}_{}'.format(approximant, det)]) * 1000 \n",
    "                                         for t0 in x_line['t0_{}_{}'.format(approximant, det)]], '.-', label = det)\n",
    "        plt.gca().set_prop_cycle(None) # Reset color cycle\n",
    "        try: # Has LIGO reported values for this approximant?:\n",
    "            ligo_parameters[x['name']][approximant]\n",
    "            app = approximant\n",
    "        except: # ... or only Overall?:\n",
    "            app = 'Overall'\n",
    "        for det in detectors:\n",
    "            plt.errorbar(ligo_parameters[x['name']][app], 0,\n",
    "                         xerr = [[ligo_parameters[x['name']][app + '_errm']], \n",
    "                                 [ligo_parameters[x['name']][app + '_errp']]], \n",
    "                         yerr = dt0[approximant][det] * 1000, capsize = 5, elinewidth = .8)\n",
    "        plt.title(r'Varying {} ({})'.format(x['label'], approximant))\n",
    "        plt.xlabel('{} {}'.format(x['label'], x['unit']))\n",
    "        plt.ylabel(r'$\\Delta t_0$ [ms]')\n",
    "        ylim = plt.gca().get_ylim()\n",
    "        plt.ylim(max(ylim[0], -10), min(ylim[1], 10)) # Constrain ylim\n",
    "        plt.legend()\n",
    "plt.tight_layout();\n",
    "plt.savefig('{}/figures/t0.pdf'.format(event), bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior\n",
    "\n",
    "$P = P_{\\rm prior}\\mathcal{L}$. For now we use a uniform prior in $\\chi_{\\rm eff}$. To connect priors in $(m_1, m_2)$ to $(\\mathcal{M}, q)$ use:\n",
    "\n",
    "$$P_{\\rm prior}(\\mathcal{M}, q) = P_{\\rm prior}(m_1, m_2) \\frac{\\left(1 + \\frac{1}{q}\\right)^{1/5}  (1 + q)^{1/5}}{q} \\mathcal{M}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Priors:\n",
    "def uniform_in_m1_m2 (M_chirp, q):\n",
    "    return M_chirp * (1 + 1/q)**.2 * (1 + q)**.2 / q\n",
    "uniform_in_m1_m2.latex = 'Uniform in $m_1, m_2$'\n",
    "uniform_in_m1_m2.text = 'Uniform in m1, m2'\n",
    "\n",
    "def uniform_in_Mchirp_q (M_chirp, q):\n",
    "    return 1\n",
    "uniform_in_Mchirp_q.latex = 'Uniform in $\\mathcal{M}, q$'\n",
    "uniform_in_Mchirp_q.text = 'Uniform in Mchirp, q'\n",
    "\n",
    "priors = [uniform_in_m1_m2, uniform_in_Mchirp_q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Slices to plot: vary the first two at marginalized third:\n",
    "slices = [#[m1_dict, m2_dict, chi_eff_dict], # Marginalize over chi_eff, (m1, m2) plot\n",
    "          [q_dict, chi_eff_dict, M_chirp_dict], # Marginalize over M_chirp, (q, chi_eff) plot\n",
    "          [M_chirp_dict, chi_eff_dict, q_dict] # Marginalize over q, (Mchirp, chi_eff) plot\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpolate** SNR on a grid on the 3D parameter space $(\\mathcal{M}, q, \\chi_{\\rm eff})$. Then use to compute a the likelihood (instead of interpolating the likelihood directly, because SNR should vary more smoothly).\n",
    "\n",
    "To plot, we note that for a 2D Gaussian $P(x, y) \\propto \\exp[-(x^2+y^2)/2)$ the $P$ contour enclosing a fraction $f$ of the events has $P_f = P/P_{\\rm max} (1-f)$. We use this as a proxy for the 90% level contour. *Warning:* This approach is very sensitive to $P_{\\rm max}$, so the original grid must be dense enough.The alternative is to integrate inside the contour and check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# *This cell assumes the independent parameters of the grid.*\n",
    "grid_indep_params = ['M_chirp', 'q', 'chi_eff']\n",
    "num = 50\n",
    "grid_1d = {}\n",
    "for par in grid_indep_params:\n",
    "    grid_1d[par] = np.linspace(parameters[par].min() + 1e-5, parameters[par].max() - 1e-5, num)\n",
    "\n",
    "grid = dict(zip(grid_indep_params, np.meshgrid(*[grid_1d[par] for par in grid_indep_params])))\n",
    "for par in grid:\n",
    "    grid[par] = grid[par].flatten()\n",
    "grid = pd.DataFrame(grid)\n",
    "for approximant in approximants:\n",
    "    grid['SNR_' + approximant] = griddata(parameters[['M_chirp', 'q', 'chi_eff']], \n",
    "                                          parameters['SNR_' + approximant].values, \n",
    "                                          (grid['M_chirp'], grid['q'], grid['chi_eff']),\n",
    "                                          method = 'linear', rescale = True)\n",
    "    L = exp(grid['SNR_' + approximant]**2/2)\n",
    "    grid['likelihood_' + approximant] = L / L.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_cols = len(approximants)\n",
    "n_rows = len(slices)\n",
    "\n",
    "for prior in priors:\n",
    "    print(prior.text + ' prior:')\n",
    "    plt.figure(figsize = (4.5 * n_cols, 3.5 * n_rows + .5))\n",
    "    plt.suptitle(prior.latex + ' prior', size = 'x-large')\n",
    "    for col, approximant in enumerate(approximants):\n",
    "        posterior = prior(parameters['M_chirp'], parameters['q']) * parameters['likelihood_' + approximant]\n",
    "        grid_posterior = prior(grid['M_chirp'], grid['q']) * grid['likelihood_' + approximant]\n",
    "        grid_posterior /= max(grid_posterior)#.flatten())\n",
    "        max_posterior = parameters.loc[posterior.idxmax()]\n",
    "        print('Maximum-posterior parameters ({}):'.format(approximant))\n",
    "        print(max_posterior, end = '\\n\\n')\n",
    "\n",
    "        # Marginalize over z and vary (x, y):\n",
    "        for row, [x, y, z] in enumerate(slices):\n",
    "            plt.subplot(n_rows, n_cols, n_cols * row + col + 1)\n",
    "            plt.title(r'Marginalization over {} ({})'.format(z['label'], approximant))\n",
    "            \n",
    "            # Marginalized over original grid:\n",
    "            z_slice = parameters[is_approx(parameters[z['name']], max_posterior[z['name']])]\n",
    "            marg_posterior = []\n",
    "            for xx, yy in z_slice[[x['name'], y['name']]].values:\n",
    "                marg_posterior.append(posterior[is_approx(parameters[x['name']], xx) & \n",
    "                                                is_approx(parameters[y['name']], yy)\n",
    "                                               ].mean())\n",
    "            marg_posterior = np.array(marg_posterior) / max(marg_posterior)\n",
    "            \n",
    "            # Marginalized over interpolated grid:\n",
    "            xy_grid = np.array([[xx, yy] for xx in grid_1d[x['name']] for yy in grid_1d[y['name']]])\n",
    "            marg_posterior_xy_grid = []\n",
    "            for xx, yy in xy_grid:\n",
    "                marg_posterior_xy_grid.append(grid_posterior[is_approx(grid[x['name']], xx) & \n",
    "                                                             is_approx(grid[y['name']], yy)\n",
    "                                                            ].mean())\n",
    "            marg_posterior_xy_grid = np.array(marg_posterior_xy_grid) / max(marg_posterior_xy_grid)\n",
    "            \n",
    "            c_90 = plt.contour(grid_1d[x['name']], grid_1d[y['name']],\n",
    "                        np.reshape(marg_posterior_xy_grid, (len(grid_1d[x['name']]), len(grid_1d[y['name']]))).T,\n",
    "                        levels = [.1]) # ~ 90% confidence contour\n",
    "            try: # Has LIGO reported values for this approximant?:\n",
    "                ligo_parameters[x['name']][approximant]\n",
    "                app = approximant\n",
    "            except: # ... or only Overall?:\n",
    "                app = 'Overall'\n",
    "            plt.errorbar(ligo_parameters[x['name']][app], ligo_parameters[y['name']][app], \n",
    "                         xerr = [[ligo_parameters[x['name']][app + '_errm']], \n",
    "                                 [ligo_parameters[x['name']][app + '_errp']]], \n",
    "                         yerr = [[ligo_parameters[y['name']][app + '_errm']], \n",
    "                                 [ligo_parameters[y['name']][app + '_errp']]], \n",
    "                         label = 'LIGO reported', ecolor = 'k', ls = 'None')\n",
    "            \n",
    "            #sc = plt.scatter(z_slice[x['name']], z_slice[y['name']], c = marg_posterior,\n",
    "            #                 cmap = 'viridis', label = '_nolegend_')\n",
    "            plt.imshow(np.reshape(marg_posterior_xy_grid, (len(grid_1d[x['name']]), len(grid_1d[y['name']]))).T,\n",
    "                       extent = [grid_1d[x['name']].min(), grid_1d[x['name']].max(),\n",
    "                                 grid_1d[y['name']].min(), grid_1d[y['name']].max()],\n",
    "                       cmap='viridis', origin = 'lower', aspect = 'auto', alpha = .5)\n",
    "            #plt.scatter(*xy_grid.transpose(), c = marg_posterior_xy_grid, alpha = .2, s = 2, cmap = 'viridis')\n",
    "            plt.plot(max_posterior[x['name']], max_posterior[y['name']], 'r+', label = 'max $P$')\n",
    "            plt.xlabel('{} {}'.format(x['label'], x['unit']))\n",
    "            plt.ylabel('{} {}'.format(y['label'], y['unit']))\n",
    "            plt.legend(framealpha = .95)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97]);\n",
    "    plt.savefig('{}/figures/{}interp.pdf'.format(event, prior.__name__), bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the quality of the of the likelihood interpolation with random samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, compute **SNR**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_parameters = pd.read_csv('{}/random_parameters'.format(event), sep = '\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_recompute_SNR = False # False: use the previous SNR if available.\n",
    "\n",
    "if not any('SNR' in col_name for col_name in random_parameters.columns):\n",
    "    random_recompute_SNR = True\n",
    "\n",
    "def random_compute_SNR(n, approximant):\n",
    "    H = np.genfromtxt('{}/random_{}/{}.dat'.format(event, approximant, n), dtype = complex)\n",
    "    SNR, t0 = {}, {}\n",
    "    for det in detectors:\n",
    "        Z = 2 * (S[det] * H.conjugate() / PSD[det]) / sqrt((abs(H)**2 / PSD[det] * df).sum())\n",
    "        z_ = fft.ifft(Z * fs, N) # The underscore is to prevent conflict with previous z\n",
    "        argmax = np.argmax(abs(z_))\n",
    "        SNR[det] = abs(z_[argmax])\n",
    "        t0[det] = times[argmax]\n",
    "    return {'SNR': sqrt(sum([SNR[det]**2 for det in detectors])), 't0': t0}\n",
    "\n",
    "if random_recompute_SNR:\n",
    "    p = Pool(cpu_count())\n",
    "    for approximant in approximants:\n",
    "        results = p.starmap(random_compute_SNR, [[n, approximant] for n in random_parameters.index])\n",
    "        random_parameters['SNR_{}'.format(approximant)] = [x['SNR'] for x in results]\n",
    "    random_parameters.to_csv('{}/random_parameters'.format(event), sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_parameters['M_chirp'] = (random_parameters['m1'] * random_parameters['m2'])**.6 \\\n",
    "                             / (random_parameters['m1'] + random_parameters['m2'])**.2\n",
    "random_parameters['q'] = random_parameters['m2'] / random_parameters['m1']\n",
    "random_parameters['chi_eff'] = (random_parameters['m1'] * random_parameters['s1z'] \\\n",
    "                                + random_parameters['m2'] * random_parameters['s2z']) \\\n",
    "                             / (random_parameters['m1'] + random_parameters['m2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the **true likelihood**, and the **interpolated likelihood**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for approximant in approximants:\n",
    "    L = exp(random_parameters['SNR_{}'.format(approximant)]**2/2)\n",
    "    random_parameters['likelihood_{}'.format(approximant)] = L / L.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# *This cell assumes the independent parameters of the grid.*\n",
    "for approximant in approximants:\n",
    "    random_parameters['interpolated_SNR_' + approximant] = \\\n",
    "        griddata(grid[['M_chirp', 'q', 'chi_eff']], \n",
    "                 grid['SNR_' + approximant].values, \n",
    "                 (random_parameters['M_chirp'], random_parameters['q'], random_parameters['chi_eff']),\n",
    "                 method = 'linear', rescale = True)\n",
    "    random_parameters['interpolated_likelihood_' + approximant] = \\\n",
    "        griddata(grid[['M_chirp', 'q', 'chi_eff']], \n",
    "                 grid['likelihood_' + approximant].values, \n",
    "                 (random_parameters['M_chirp'], random_parameters['q'], random_parameters['chi_eff']),\n",
    "                 method = 'linear', rescale = True)\n",
    "    #L = exp(random_parameters['interpolated_SNR_' + approximant]**2/2)\n",
    "    #random_parameters['interpolated_likelihood_' + approximant] = L / L.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot** the interpolated vs true SNR and likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cols = len(approximants)\n",
    "n_rows = 2\n",
    "plt.figure(figsize = (4 * n_cols, 4 * n_rows))\n",
    "for col, approximant in enumerate(approximants):\n",
    "    plt.subplot(n_rows, n_cols, col + 1, aspect = 'equal')\n",
    "    plt.title('SNR ({})'.format(approximant))\n",
    "    plt.plot(random_parameters['SNR_' + approximant], random_parameters['interpolated_SNR_' + approximant], \n",
    "             '.', ls = 'None')\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    plt.plot([0, 1e5], [0, 1e5], c = 'lightgrey', zorder = 0) # y=x line\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlabel('True SNR')\n",
    "    plt.ylabel('Interpolated SNR')\n",
    "    \n",
    "    plt.subplot(n_rows, n_cols, n_cols + col + 1, aspect = 'equal')\n",
    "    plt.title('$\\mathcal{{L}}$ ({})'.format(approximant))\n",
    "    plt.plot(random_parameters['likelihood_' + approximant], \n",
    "             random_parameters['interpolated_likelihood_' + approximant], \n",
    "             '.', ls = 'None')\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    plt.plot([0, 1e5], [0, 1e5], c = 'lightgrey', zorder = 0) # y=x line\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlabel('True $\\mathcal{L}$')\n",
    "    plt.ylabel('Interpolated $\\mathcal{L}$')\n",
    "plt.tight_layout()\n",
    "plt.savefig('{}/figures/true_vs_interpolated_L.pdf'.format(event), bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "n_cols = len(approximants)\n",
    "n_rows = len(slices) + 1\n",
    "\n",
    "for prior in priors:\n",
    "    print(prior.text + ' prior:')\n",
    "    plt.figure(figsize = (4.7 * n_cols, 3.5 * n_rows + .5))\n",
    "    plt.suptitle(prior.latex + ' prior', size = 'x-large')\n",
    "    for col, approximant in enumerate(approximants):\n",
    "        posterior = prior(parameters['M_chirp'], parameters['q']) * parameters['likelihood_' + approximant]\n",
    "        max_posterior = parameters.loc[posterior.idxmax()]\n",
    "        print('Maximum-posterior parameters ({}):'.format(approximant))\n",
    "        print(max_posterior, end = '\\n\\n')\n",
    "\n",
    "        # 3D scatter plot:\n",
    "        ax = plt.subplot(n_rows, n_cols, col + 1, projection = '3d')\n",
    "        sc = ax.scatter(parameters['m1'], parameters['m2'], parameters['chi_eff'], s = 1,\n",
    "                        c = posterior, cmap = 'viridis', label = '_nolegend_')\n",
    "        ax.scatter(max_posterior['m1'], max_posterior['m2'], max_posterior['chi_eff'], c = 'r', \n",
    "                   label = 'max $P$')\n",
    "        plt.xlabel('$m_1$ $[M_\\odot]$')\n",
    "        plt.ylabel('$m_2$ $[M_\\odot]$')\n",
    "        ax.set_zlabel(r'$\\chi_{\\rm eff}$')\n",
    "        plt.title('Posterior ({})'.format(approximant))\n",
    "\n",
    "        # Marginalize over z and vary (x, y):\n",
    "        for row, [x, y, z] in enumerate(slices):\n",
    "            plt.subplot(n_rows, n_cols, n_cols * (row + 1) + col + 1)\n",
    "            plt.title(r'Marginalization over {} ({})'.format(z['label'], approximant))\n",
    "            z_slice = parameters[is_approx(parameters[z['name']], max_posterior[z['name']])]\n",
    "            marg_posterior = []\n",
    "            for x_, y_ in z_slice[[x['name'], y['name']]].values:\n",
    "                marg_posterior.append(posterior[is_approx(parameters[x['name']], x_) & \n",
    "                                                is_approx(parameters[y['name']], y_)\n",
    "                                               ].mean())\n",
    "            try: # Has LIGO reported values for this approximant?:\n",
    "                ligo_parameters[x['name']][approximant]\n",
    "                app = approximant\n",
    "            except: # ... or only Overall?:\n",
    "                app = 'Overall'\n",
    "            plt.errorbar(ligo_parameters[x['name']][app], ligo_parameters[y['name']][app], \n",
    "                         xerr = [[ligo_parameters[x['name']][app + '_errm']], \n",
    "                                 [ligo_parameters[x['name']][app + '_errp']]], \n",
    "                         yerr = [[ligo_parameters[y['name']][app + '_errm']], \n",
    "                                 [ligo_parameters[y['name']][app + '_errp']]], \n",
    "                         label = event)\n",
    "            sc = plt.scatter(z_slice[x['name']], z_slice[y['name']], c = marg_posterior,\n",
    "                             cmap = 'viridis', label = '_nolegend_')\n",
    "            plt.plot(max_posterior[x['name']], max_posterior[y['name']], 'r+', label = 'max $P$')\n",
    "            plt.xlabel('{} {}'.format(x['label'], x['unit']))\n",
    "            plt.ylabel('{} {}'.format(y['label'], y['unit']))\n",
    "            plt.legend(framealpha = .95)\n",
    "    plt.tight_layout(rect=[0, 0, .93, 0.97]);\n",
    "    plt.savefig('{}/figures/{}.pdf'.format(event, prior.__name__), bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
