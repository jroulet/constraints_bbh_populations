{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate signal parameters\n",
    "\n",
    "...by computing the likelihood on a grid.\n",
    "\n",
    "Notation:\n",
    "* Capital letters refer to Fourier components, e.g.: `h` = $h(t)$ and `H` = $\\tilde h(f)$.\n",
    "* $s(t) = h(t) + n(t)$, (strain = template + noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.optimize import brentq as brentq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#event = 'GW150914'\n",
    "#event = 'GW151226'\n",
    "#event = 'LVT151012'\n",
    "#event = 'GW170104'\n",
    "event = 'GW170608'\n",
    "#event = 'GW170814'\n",
    "\n",
    "approximants = ['IMRPhenomD',\n",
    "                'SEOBNRv4_ROM'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "* template parameters and SNR\n",
    "* parameter values reported by LIGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = pd.read_csv(event + '/parameter_grid', sep='\\s+')\n",
    "\n",
    "ligo_parameters = pd.read_csv('{0}/{0}_LIGO_parameters'.format(event), sep='\\s+', comment='#')\n",
    "\n",
    "with open(event + '/grid_metadata') as  grid_metadata:\n",
    "    grid_params = grid_metadata.readline().strip().split()\n",
    "    original_num = dict(zip(grid_params, [int(x) for x in grid_metadata.readline().strip().split()]))\n",
    "original_nums = np.array(list(original_num.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute likelihood\n",
    "Interpolate the SNR on a grid on the 3D parameter space $(\\mathcal{M}, q, \\chi_{\\rm eff})$. Then use to compute a the likelihood (instead of interpolating the likelihood directly, because SNR should vary more smoothly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the 1d grids, interpolation grid and 2d grids\n",
    "zoom =  2  # Refine grid by this factor with interpolation (make it integer)\n",
    "num = dict(zip(grid_params, original_nums * zoom)) # New grid size\n",
    "\n",
    "grid_1d, original_grid_1d = {}, {}\n",
    "for par in grid_params:\n",
    "    grid_1d[par] = np.linspace(parameters[par].min(), parameters[par].max(), num[par])\n",
    "    original_grid_1d[par] = np.linspace(parameters[par].min(), parameters[par].max(), original_num[par])\n",
    "\n",
    "grid = dict(zip(grid_params, np.meshgrid(*[grid_1d[par] for par in grid_params], indexing='ij')))\n",
    "\n",
    "grid_2d_params = [(x_par, y_par) for i, x_par in enumerate(grid_params) for y_par in grid_params[i + 1:]]\n",
    "grid_2d = {}\n",
    "for xy_pars in grid_2d_params:\n",
    "    grid_2d[xy_pars] = dict(zip(xy_pars, np.meshgrid(*[grid_1d[par] for par in xy_pars], indexing='ij')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_grid = {}\n",
    "for par in grid_params:\n",
    "    original_grid[par] = np.reshape(parameters[par].values, (original_nums))\n",
    "# Consistency check:\n",
    "assert(np.allclose([original_grid[par] for par in grid_params], \n",
    "                   np.meshgrid(*[original_grid_1d[par] for par in grid_params], indexing='ij'), atol=1e-2)), \\\n",
    "    'There was some problem reconstructing the parameter_grid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SNR_IMRPhenomD'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/home/javier/.anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2392\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2393\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SNR_IMRPhenomD'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d8c751029de8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Interpolate SNR and compute likelihood:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mapproximant\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mapproximants\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     grid['SNR', approximant] = ndimage.zoom(np.reshape(parameters['SNR_' + approximant].values, \n\u001b[0m\u001b[1;32m      4\u001b[0m                                                        \u001b[0;34m(\u001b[0m\u001b[0moriginal_nums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                       ), zoom, order=1)\n",
      "\u001b[0;32m/home/javier/.anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/javier/.anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/javier/.anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/javier/.anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/javier/.anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2393\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2395\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SNR_IMRPhenomD'"
     ]
    }
   ],
   "source": [
    "# Interpolate SNR and compute likelihood:\n",
    "for approximant in approximants:\n",
    "    grid['SNR', approximant] = ndimage.zoom(np.reshape(parameters['SNR_' + approximant].values, \n",
    "                                                       (original_nums)\n",
    "                                                      ), zoom, order=1)\n",
    "    L = np.exp(grid['SNR', approximant]**2 / 2)\n",
    "    grid['likelihood', approximant] = L / L.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginalized posteriors\n",
    "\n",
    "$P = P_{\\rm prior}\\mathcal{L}$. For now we use a uniform prior in $\\chi_{\\rm eff}$. To connect priors in $(m_1, m_2)$ to $(\\mathcal{M}, q)$ use:\n",
    "\n",
    "$$P_{\\rm prior}(\\mathcal{M}, q) = P_{\\rm prior}(m_1, m_2) \\frac{\\left(1 + \\frac{1}{q}\\right)^{1/5}  (1 + q)^{1/5}}{q} \\mathcal{M}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Heaviside(x):\n",
    "    return x >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the priors:\n",
    "def uniform_in_m1_m2_chieff(M_chirp, q, **kwargs):\n",
    "    return M_chirp * (1+1/q)**.2 * (1+q)**.2 / q\n",
    "uniform_in_m1_m2_chieff.latex = r'Uniform in $m_1, m_2, \\chi_{{\\rm eff}}$'\n",
    "uniform_in_m1_m2_chieff.text = 'Uniform in m1, m2, Xeff'\n",
    "\n",
    "def uniform_in_m1_m2_chi1_chi2(M_chirp, q, chi_eff, **kwargs):  # The one LIGO uses \n",
    "    return M_chirp * (1+1/q)**.2 * (1+q)**.2 / q * (\n",
    "        -((1+q)*(Heaviside(-((1+q)*(-1+chi_eff)))*((1+q)*(-1+chi_eff)-(1+q*(-1+chi_eff)+chi_eff)\n",
    "        *Heaviside(-1+q-(1+q)*chi_eff))+(1-q-(1+q)*chi_eff+(1+q)*(1+chi_eff)\n",
    "        *Heaviside(-((1+q)*(1+chi_eff))))*Heaviside(1-chi_eff-q*(1+chi_eff))))/(4.*q))\n",
    "uniform_in_m1_m2_chi1_chi2.latex = r'Uniform in $m_1, m_2, \\chi_1, \\chi_2$'\n",
    "uniform_in_m1_m2_chi1_chi2.text = 'Uniform in m1, m2, X1, X2'\n",
    "\n",
    "def uniform_in_Mchirp_q_chieff(M_chirp, **kwargs):\n",
    "    return np.ones_like(M_chirp)\n",
    "uniform_in_Mchirp_q_chieff.latex = r'Uniform in $\\mathcal{{M}}, q, \\chi_{{\\rm eff}}$'\n",
    "uniform_in_Mchirp_q_chieff.text = 'Uniform in Mchirp, q, Xeff'\n",
    "\n",
    "priors = [#uniform_in_m1_m2_chieff,\n",
    "          uniform_in_m1_m2_chi1_chi2,\n",
    "          #uniform_in_Mchirp_q_chieff\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for prior in priors:\n",
    "    grid[prior.__name__] = prior(**{par:grid[par] for par in grid_params})\n",
    "    grid[prior.__name__] /= grid[prior.__name__].sum()\n",
    "    for approximant in approximants:\n",
    "        grid['posterior', prior.__name__, approximant] = grid[prior.__name__] * grid['likelihood', approximant]\n",
    "        grid['posterior', prior.__name__, approximant] /= grid['posterior', prior.__name__, approximant].sum()\n",
    "    \n",
    "    #Compute 1d marginalized priors and posteriors:\n",
    "    for i, x_par in enumerate(grid_params):\n",
    "        js = tuple(j for j in range(len(grid_params)) if j != i) # Marginalize over these axes\n",
    "        grid_1d[prior.__name__, x_par] = grid[prior.__name__].sum(axis=js)\n",
    "        for approximant in approximants:\n",
    "            grid_1d['posterior', prior.__name__, approximant, x_par] \\\n",
    "                = grid['posterior', prior.__name__, approximant].sum(axis=js)\n",
    "\n",
    "    # Compute 2d marginalized posteriors\n",
    "    for xy_pars in grid_2d_params:\n",
    "        for approximant in approximants:\n",
    "            js = tuple(j for j, z in enumerate(grid_params) if not z in xy_pars) # Marginalize over these axes\n",
    "            grid_2d[xy_pars]['posterior', prior.__name__, approximant] \\\n",
    "                = grid['posterior', prior.__name__, approximant].sum(axis=js)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find parameter estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "median, bounds_estimate, err_estimate = {}, {}, {}\n",
    "for prior in priors:\n",
    "    for approximant in approximants:\n",
    "        for par in grid_params:\n",
    "            cumulative_P = UnivariateSpline(\n",
    "                grid_1d[par], np.cumsum(grid_1d['posterior', prior.__name__, approximant, par]) - .5, s=0)\n",
    "            median[prior.__name__, approximant, par] = cumulative_P.roots()[0]\n",
    "            \n",
    "            P_level = brentq(lambda level, P: P[P > level].sum()-.9, 0, 1, \n",
    "                             args=(grid_1d['posterior', prior.__name__, approximant, par]))\n",
    "            P_spline = UnivariateSpline(grid_1d[par], \n",
    "                                        grid_1d['posterior', prior.__name__, approximant, par] - P_level,\n",
    "                                        s=0)\n",
    "            roots = P_spline.roots()\n",
    "            bounds_estimate[prior.__name__, approximant, par] = np.array([roots[0], roots[-1]])\n",
    "            if grid_1d['posterior', prior.__name__, approximant, par][0] > P_level:\n",
    "                bounds_estimate[prior.__name__, approximant, par][0] = grid_1d[par][0]\n",
    "            if grid_1d['posterior', prior.__name__, approximant, par][-1] > P_level:\n",
    "                bounds_estimate[prior.__name__, approximant, par][1] = grid_1d[par][-1]\n",
    "            err_estimate[prior.__name__, approximant, par] = abs(median[prior.__name__, approximant, par]\n",
    "                - bounds_estimate[prior.__name__, approximant, par])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find % confidence contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fractions = [.5, .9]  # Probability enclosed by contours\n",
    "fractions = sorted(fractions, reverse=True)  # So that the P levels are increasing\n",
    "levels = {}\n",
    "for prior in priors:\n",
    "    for approximant in approximants:\n",
    "        for xy_pars in grid_2d_params:\n",
    "            levels[prior.__name__, approximant, xy_pars] = [brentq(\n",
    "                lambda level, P: P[P > level].sum()-fraction, 0, 1,\n",
    "                args=(grid_2d[xy_pars]['posterior', prior.__name__, approximant])) for fraction in fractions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latex = {'M_chirp': r'$\\mathcal{{M}}$',\n",
    "         'q': r'$q$',\n",
    "         'chi_eff': r'$\\chi_{{\\rm eff}}$'}\n",
    "unit = {'M_chirp': r' [$M_\\odot$]',\n",
    "        'q': '', 'chi_eff': ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def latex_val_err(v, e):  # e == [err_m, err_p]\n",
    "    n_digits = max(0, *[int(np.ceil(-np.log10(e_))) for e_ in e])\n",
    "    r = lambda a, n: round(a, n) if n > 0 else int(round(a))\n",
    "    return '${}_{{-{}}}^{{+{}}}$'.format(r(v, n_digits), *[r(e_, n_digits) for e_ in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.clf();\n",
    "n_cols = n_rows = len(grid_params)\n",
    "for prior in priors:\n",
    "    for approximant in approximants:\n",
    "        try:  # Has LIGO reported values for this approximant?:\n",
    "            ligo_parameters[x_par][approximant]\n",
    "            app = approximant\n",
    "        except:  # ... or only Overall?:\n",
    "            app = 'Overall'\n",
    "        \n",
    "        fig, ax = plt.subplots(n_rows, n_cols, figsize=(2.9 * n_cols, 2.9 * n_rows + .5));\n",
    "        plt.suptitle('{} - {} prior ({})'.format(event, prior.latex, approximant), size='x-large')\n",
    "                                   \n",
    "        # Plot 2D posteriors (off-diagonal in the triangle)\n",
    "        for row, y_par in list(enumerate(grid_params))[1:]:\n",
    "            for col, x_par in list(enumerate(grid_params))[:row]:\n",
    "                plt.sca(ax[row][col])\n",
    "                xy_posterior = grid_2d[x_par, y_par]['posterior', prior.__name__, approximant].T\n",
    "                \n",
    "                plt.imshow(xy_posterior, extent=[grid_1d[x_par].min(), grid_1d[x_par].max(),\n",
    "                                                 grid_1d[y_par].min(), grid_1d[y_par].max()],\n",
    "                           cmap='viridis', origin='lower', aspect='auto', alpha=.5)\n",
    "                \n",
    "                contours = plt.contour(grid_1d[x_par], grid_1d[y_par], xy_posterior,\n",
    "                                       levels=levels[prior.__name__, approximant, (x_par, y_par)])\n",
    "                for i in range(len(fractions)):\n",
    "                    contours.collections[i].set_label('{:.0f}% c.l.'.format(100*fractions[i]))\n",
    "                    \n",
    "                plt.errorbar(ligo_parameters[x_par][app],\n",
    "                             ligo_parameters[y_par][app],\n",
    "                             xerr=[[ligo_parameters[x_par][app + '_errm']],\n",
    "                                   [ligo_parameters[x_par][app + '_errp']]],\n",
    "                             yerr=[[ligo_parameters[y_par][app + '_errm']],\n",
    "                                   [ligo_parameters[y_par][app + '_errp']]],\n",
    "                             label='LIGO reported', color='k', ecolor='k', ls='None', fmt='.')\n",
    "        \n",
    "        # Plot 1D posteriors (diagonal)\n",
    "        for i, par in enumerate(grid_params):\n",
    "            plt.sca(ax[i][i])\n",
    "            ligo_val = ligo_parameters[par][app]\n",
    "            ligo_err = [[ligo_parameters[par][app + '_errm']], [ligo_parameters[par][app + '_errp']]]\n",
    "            plt.errorbar(ligo_val, grid_1d['posterior', prior.__name__, approximant, par].max() / 2,\n",
    "                         xerr=ligo_err, ls='None', fmt='.', color='k', ecolor='k')\n",
    "            plt.axvline(median[prior.__name__, approximant, par], alpha=.4)\n",
    "            plt.axvspan(*bounds_estimate[prior.__name__, approximant, par], alpha=.1)\n",
    "            plt.title('{}$=${}'.format(latex[par], latex_val_err(median[prior.__name__, approximant, par],\n",
    "                                                                 err_estimate[prior.__name__, approximant, par])))\n",
    "            plt.plot(grid_1d[par], grid_1d['posterior', prior.__name__, approximant, par], label='Posterior')\n",
    "            plt.plot(grid_1d[par], grid_1d[prior.__name__, par], label='Prior')\n",
    "        \n",
    "        # Embellish\n",
    "        handles_1d, labels_1d = ax[0][0].get_legend_handles_labels()\n",
    "        handles_2d, labels_2d = ax[1][0].get_legend_handles_labels()\n",
    "        fig.legend(handles_1d + handles_2d, labels_1d + labels_2d, \n",
    "                   loc='upper left', bbox_to_anchor=(.4, .91), frameon=False)\n",
    "        for col, x_par in enumerate(grid_params):\n",
    "            ax[n_rows-1][col].set_xlabel(latex[x_par] + unit[x_par], size='large')\n",
    "            for row in range(n_rows-1):\n",
    "                ax[row][col].tick_params(labelbottom='off')\n",
    "        for row, y_par in list(enumerate(grid_params))[1:]:\n",
    "            ax[row][0].set_ylabel(latex[y_par] + unit[y_par], size='large')\n",
    "            for col in range(1, n_cols):\n",
    "                ax[row][col].tick_params(labelleft='off')\n",
    "        for i in range(len(grid_params)):\n",
    "            ax[i][i].tick_params(axis='y', left='off', labelleft='off')\n",
    "        for row in range(n_rows-1):\n",
    "            for col in range(row+1, n_cols):\n",
    "                ax[row][col].axis('off')\n",
    "        for col in range(n_cols):\n",
    "            for row in range(1, n_rows):\n",
    "                ax[0][col].get_shared_x_axes().join(ax[0][col], ax[row][col])\n",
    "        for row in range(n_rows):\n",
    "            for col in range(1, row):\n",
    "                ax[row][0].get_shared_y_axes().join(ax[row][0], ax[row][col])\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96]);\n",
    "        plt.subplots_adjust(hspace=0.04, wspace=0.04);\n",
    "        \n",
    "        plt.savefig('{0}/figures/{0}_{1}_{2}.pdf'.format(event, prior.__name__, approximant), \n",
    "                    bbox_inches='tight')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
